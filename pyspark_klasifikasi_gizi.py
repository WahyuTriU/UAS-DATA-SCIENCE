# -*- coding: utf-8 -*-
"""PySpark Klasifikasi Gizi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZvCk_TJP0bGDx_HZYuAEHzNhbCCXpat3

# Import Library
"""

pip install pyspark

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
from pyspark.ml.feature import VectorAssembler
from pyspark.ml import Pipeline
from pyspark.ml.feature import StringIndexer, IndexToString
from pyspark.sql import SparkSession
from pyspark.ml.classification import DecisionTreeClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.mllib.evaluation import MulticlassMetrics
from pyspark.sql import Row
from pyspark.sql.functions import when

spark = SparkSession.builder.appName("GiziBalitaClassification").getOrCreate()

"""# Load Data"""

data_path = "/content/datafix.csv"
df = spark.read.csv(data_path, header=True, inferSchema=True)
df.show()

# Mengonversi PySpark DataFrame ke Pandas DataFrame
pandas_df = df.toPandas()

# Hitung jumlah setiap label
label_counts = pandas_df['status'].value_counts()

# Plot bar chart
plt.figure(figsize=(8, 6))
label_counts.plot(kind='bar', color='skyblue')
plt.title('Jumlah Data untuk Setiap Label Gizi')
plt.xlabel('Label Gizi')
plt.ylabel('Jumlah Data')
plt.show()

"""# Preprocessing"""

# StringIndexer untuk mengubah label menjadi angka
label_indexer = StringIndexer(inputCol="status", outputCol="label")

# Menggabungkan fitur-fitur ke dalam satu vektor
feature_cols = ["usia", "berat", "tinggi"]
feature_assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")

# Membuat pipeline untuk preprocessing
pipeline = Pipeline(stages=[label_indexer, feature_assembler])

# Mengaplikasikan pipeline ke data
preprocessed_data = pipeline.fit(df).transform(df)
preprocessed_data.show()

"""# Pembgaian data"""

train_data, test_data = preprocessed_data.randomSplit([0.8, 0.2], seed=42)

"""# Training"""

# Membuat model Decision Tree
dt_classifier = DecisionTreeClassifier(featuresCol="features", labelCol="label")

# Melatih model
model = dt_classifier.fit(train_data)

"""# Evaluasi"""

# Membuat evaluator
evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")

# Mengevaluasi model
accuracy = evaluator.evaluate(model.transform(test_data))
print(f"Accuracy: {accuracy}")

# Precision
precision_evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedPrecision")
precision = precision_evaluator.evaluate(model.transform(test_data))
print(f"Weighted Precision: {precision}")

# Recall
recall_evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedRecall")
recall = recall_evaluator.evaluate(model.transform(test_data))
print(f"Weighted Recall: {recall}")

# F1 Score
f1_evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="f1")
f1_score = f1_evaluator.evaluate(model.transform(test_data))
print(f"F1 Score: {f1_score}")

# Mendefinisikan pemetaan dari label numerik ke label teks
label_mapping = {
    0: "Gizi Kurang",
    1: "Gizi Baik",
    2: "Gizi Lebih"
}

# Menggunakan model untuk melakukan prediksi pada data pengujian
predictions = model.transform(test_data)

# Mendapatkan kolom "prediction" dan "label" sebagai RDD
prediction_and_label = predictions.select("prediction", "label").rdd

# Membuat objek MulticlassMetrics
metrics = MulticlassMetrics(prediction_and_label)

# Mendapatkan matriks kebingungan
confusion_matrix = metrics.confusionMatrix().toArray()

# Mendapatkan label dalam bentuk numerik
labels_numeric = sorted(predictions.select("label").distinct().rdd.map(lambda r: r[0]).collect())

# Menampilkan confusion matrix dengan label teks
print("Confusion Matrix:")
for i in range(len(labels_numeric)):
    label_numeric = labels_numeric[i]
    label_text = label_mapping[label_numeric]
    row = confusion_matrix[i, :]
    print(f"{label_text}: {row}")

# Membuat heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix, annot=True, fmt="g", cmap="Blues", xticklabels=label_mapping.values(), yticklabels=label_mapping.values())
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

"""# Prediksi Data Baru"""

# Contoh data baru
new_data = [
    Row(usia=7, berat=22, tinggi=123),
    Row(usia=8, berat=15, tinggi=115),
    Row(usia=8, berat=25, tinggi=120),
    # Tambahkan data baru sesuai dengan format kolom yang telah Anda tentukan
]

# Konversi data menjadi DataFrame
new_data_df = spark.createDataFrame(new_data)

# Menggabungkan fitur-fitur ke dalam satu vektor
feature_cols = ["usia", "berat", "tinggi"]
feature_assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")

new_data_df = feature_assembler.transform(new_data_df)

# Mengaplikasikan pipeline ke data baru
new_data_transformed = model.transform(new_data_df)

# Dapatkan label yang sesuai dengan setiap indeks
labels = trained_pipeline.stages[0].labels  # Indeks 0 menunjukkan StringIndexer di pipeline

# Menambahkan kolom baru dengan label teks
new_data_transformed = new_data_transformed.withColumn(
    "predicted_status_text",
    when(new_data_transformed["prediction"] == 0, labels[0])
    .when(new_data_transformed["prediction"] == 1, labels[1])
    .when(new_data_transformed["prediction"] == 2, labels[2])
)

# Tampilkan hasil prediksi
new_data_transformed.select("usia", "berat", "tinggi", "predicted_status_text").show()